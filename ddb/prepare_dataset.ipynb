{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "## Data Understanding\n",
    "Images were obtained from two wildlife cameras (a Browning and Reconyx) set up near a beaver lodge on Lake Sammamish, Washington. Over 2,000 images were collected between April and June, 2019. Approximately 70% of the images contain beaver instances, the remaining are false triggers or other animals (roof rat, raccoon, squirrel, muskrat, otter, rabbit, frog, and various bird species). Most of the images are grayscale because the animals are more active at night. Both cameras were set to be motion activated and take at least 3 pictures when triggered. The date/time was off on the Browning camera and images are in weekly zipfiles with duplicate names across zipfiles. Challenges to object detection include imbalanced dataset (for non-beaver species), small instances (i.e. just tip of beaver tail), blur, grayscale, truncation, and occlusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data is large, so before adding any data to my repo I made a data directory and added it to my .gitignore file. Any files and folders that were too big for GitHub I added to .gitignore and stored in a Google Cloud Storage Bucket. I used [Photos for macOS](https://www.apple.com/macos/photos/) and [ExifRenamer](https://www.macupdate.com/app/mac/10043/exifrenamer) to correct datetimes and rename all images by site, location, and datetime. There is only one site so far (s1). The Reconyx is camera 1 (c1), the Browning is camera 2 (c2). An example name for an image taken on the Reconyx on April 11th, 2019 at 9:30:56 a.m. looks like this s1c120190411_093056.jpg. Cleaned images were placed in a folder named ddb/data/images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used [LabelImg](https://github.com/tzutalin/labelImg) to make bounding boxes around animal instances in each image. If the image contained no animal instances I verified the image to create an annotation file with no bounding boxes. LabelImg creates a .xml file for each image. Annotations were generated to the folder ddb/data/annots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to make two sets of data. A subset that contains only beaver images and a full dataset. For the beaver subset I made a train and test directory in my data directory, and ran the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions.data_preprocessing import make_species_xml_list\n",
    "from model_functions.data_preprocessing import train_test_split_data\n",
    "from model_functions.data_preprocessing import make_annot_list\n",
    "import xml.etree.ElementTree as et\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "beaver_list = make_species_xml_list('beaver', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_data(beaver_list,\n",
    "                      data_dir,\n",
    "                      test_size=0.2, \n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed the train and test files as test_beaver and train_beaver. Then I made another train and test directory and repeated with the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_list = make_annot_list(data_dir)\n",
    "train_test_split_data(annot_list,\n",
    "                      data_dir,\n",
    "                      test_size=0.2,\n",
    "                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I made label maps for the beaver subset (beaver_label_map.pbtxt)and the whole dataset (species_label_map.pbtxt) in ddb/annotations. Label maps are pretty straight forward and map each image label to an integer.\n",
    "\n",
    "I used the following code from the [Tensorflow Object Detection API Tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#creating-label-map) to make tensorflow records of the train and test data. First I added the xml_to_csv and generate_tfrecord scripts to my model_functions directory. Second, I moved into my model_functions directory in my terminal and ran the xml_to_csv script to convert xml_files to a csv file. I added the csv files to the data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# create train data\n",
    "python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv\n",
    "\n",
    "# create test data\n",
    "python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then I ran the generate_tfrecord script to convert those csv files to tfrecords. I only did this for the beaver data. Expanding to include other species is a future goal for the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# create train data\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv\n",
    "--img_path=<PATH_TO_IMAGES_FOLDER>/train --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
    "\n",
    "# create test data\n",
    "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv\n",
    "--img_path=<PATH_TO_IMAGES_FOLDER>/test\n",
    "--output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready to train on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
